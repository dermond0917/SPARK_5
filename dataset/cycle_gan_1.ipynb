{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycle_gan_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dermond0917/SPARK_5/blob/master/dataset/cycle_gan_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "El5QxeRIqoty",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Building Generator**"
      ]
    },
    {
      "metadata": {
        "id": "jpc_7NiQnReI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_f_g=32 # Number of filters in first layer of generator\n",
        "num_f_d=64 # Number of filters in first layer of discriminator\n",
        "batch_size=1\n",
        "pool_size=50\n",
        "img_width=256\n",
        "img_height=256\n",
        "img_depth=3 #RGB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iO88AmmaqyqW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoding:"
      ]
    },
    {
      "metadata": {
        "id": "Ai-TSsPQobdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#output_c1=general_conv2d(input,num_f_g,window_width=7,window_height=7,stride_width=1,stride_height=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E03Cdvj-pt4g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def general_conv2d(inputconv,o_d=64,f_w=7,f_h=7,s_w=1,s_h=1):\n",
        "    with tf.variable_scope(name):\n",
        "       conv = tf.contrib.layers.conv2d(inputconv, num_features, [window_width, window_height], [stride_width, stride_height],\n",
        "                                        padding, activation_fn=None, weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                                        biases_initializer=tf.constant_initializer(0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCz2dZ3Dq7NA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transformation:"
      ]
    },
    {
      "metadata": {
        "id": "rkdQMsH6qUq8",
        "colab_type": "code",
        "outputId": "0d10f571-81a6-476a-f4c8-fd626cf2005f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "o_r1 = build_resnet_block(o_enc_A, num_features=64*4)\n",
        "o_r2 = build_resnet_block(o_r1, num_features=64*4)\n",
        "o_r3 = build_resnet_block(o_r2, num_features=64*4)\n",
        "o_r4 = build_resnet_block(o_r3, num_features=64*4)\n",
        "o_r5 = build_resnet_block(o_r4, num_features=64*4)\n",
        "o_enc_B = build_resnet_block(o_r5, num_features=64*4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-17413385eabe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mo_r1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_enc_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mo_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_r1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mo_r3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_r2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mo_r4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_r3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mo_r5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_r4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resnet_block' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DAleObhJqXHe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resnet_blocks(input_res, num_features):\n",
        "\n",
        "    out_res_1 = general_conv2d(input_res, num_features,\n",
        "                               window_width=3,\n",
        "                               window_heigth=3,\n",
        "                               stride_width=1,\n",
        "                               stride_heigth=1)\n",
        "    out_res_2 = general_conv2d(out_res_1, num_features,\n",
        "                               window_width=3,\n",
        "                               window_heigth=3,\n",
        "                               stride_width=1,\n",
        "                               stride_heigth=1)\n",
        "    return (out_res_2 + input_res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8MBixSHrGdf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decoding:"
      ]
    },
    {
      "metadata": {
        "id": "qf-C-4ggqZ2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "o_d1 = general_deconv2d(o_enc_B, num_features=ngf*2 window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "o_d2 = general_deconv2d(o_d1, num_features=ngf, window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "gen_B = general_conv2d(o_d2, num_features=3, window_width=7, window_height=7, stride_width=1, stride_height=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-JBkMrDqeOh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(input_gen):\n",
        "    o_c1 = general_conv2d(input_gen, num_features=ngf, window_width=7, window_height=7, stride_width=1, stride_height=1)\n",
        "    o_c2 = general_conv2d(o_c1, num_features=ngf*2, window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "    o_enc_A = general_conv2d(o_c2, num_features=ngf*4, window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "\n",
        "    # Transformation\n",
        "    o_r1 = build_resnet_block(o_enc_A, num_features=64*4)\n",
        "    o_r2 = build_resnet_block(o_r1, num_features=64*4)\n",
        "    o_r3 = build_resnet_block(o_r2, num_features=64*4)\n",
        "    o_r4 = build_resnet_block(o_r3, num_features=64*4)\n",
        "    o_r5 = build_resnet_block(o_r4, num_features=64*4)\n",
        "    o_enc_B = build_resnet_block(o_r5, num_features=64*4)\n",
        "\n",
        "    #Decoding\n",
        "    o_d1 = general_deconv2d(o_enc_B, num_features=ngf*2 window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "    o_d2 = general_deconv2d(o_d1, num_features=ngf, window_width=3, window_height=3, stride_width=2, stride_height=2)\n",
        "    gen_B = general_conv2d(o_d2, num_features=3, window_width=7, window_height=7, stride_width=1, stride_height=1)\n",
        "\n",
        "    return gen_B\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjsn-6bzrlF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the discriminator"
      ]
    },
    {
      "metadata": {
        "id": "w_5IcpIbqkVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "o_c1 = general_conv2d(input_disc, ndf, f, f, 2, 2)\n",
        "o_c2 = general_conv2d(o_c1, ndf*2, f, f, 2, 2)\n",
        "o_enc_A = general_conv2d(o_c2, ndf*4, f, f, 2, 2)\n",
        "o_c4 = general_conv2d(o_enc_A, ndf*8, f, f, 2, 2)\n",
        "decision = general_conv2d(o_c4, 1, f, f, 1, 1, 0.02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqXKtD4OrvD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the model"
      ]
    },
    {
      "metadata": {
        "id": "BvnZa3ubromk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_A\")\n",
        "input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_B\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxYWExVesGR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gen_B = build_generator(input_A, name=\"generator_AtoB\")\n",
        "gen_A = build_generator(input_B, name=\"generator_BtoA\")\n",
        "dec_A = build_discriminator(input_A, name=\"discriminator_A\")\n",
        "dec_B = build_discriminator(input_B, name=\"discriminator_B\")\n",
        "\n",
        "dec_gen_A = build_discriminator(gen_A, \"discriminator_A\")\n",
        "dec_gen_B = build_discriminator(gen_B, \"discriminator_B\")\n",
        "cyc_A = build_generator(gen_B, \"generator_BtoA\")\n",
        "cyc_B = build_generator(gen_A, \"generator_AtoB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJIGEeBssNq9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ]
    },
    {
      "metadata": {
        "id": "qR5AMkSFsaIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discriminator loss"
      ]
    },
    {
      "metadata": {
        "id": "0FJusq5wsJ2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "D_A_loss_1 = tf.reduce_mean(tf.squared_difference(dec_A,1))\n",
        "D_B_loss_1 = tf.reduce_mean(tf.squared_difference(dec_B,1))\n",
        "\n",
        "D_A_loss_2 = tf.reduce_mean(tf.square(dec_gen_A))\n",
        "D_B_loss_2 = tf.reduce_mean(tf.square(dec_gen_B))\n",
        "\n",
        "D_A_loss = (D_A_loss_1 + D_A_loss_2)/2\n",
        "D_B_loss = (D_B_loss_1 + D_B_loss_2)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZkC2EWAsezg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generator loss"
      ]
    },
    {
      "metadata": {
        "id": "kF_nHqA8shh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g_loss_B_1 = tf.reduce_mean(tf.squared_difference(dec_gen_A,1))\n",
        "g_loss_A_1 = tf.reduce_mean(tf.squared_difference(dec_gen_A,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d9NFbRRaskfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cyclic loss"
      ]
    },
    {
      "metadata": {
        "id": "eR3KAKBCsntC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cyc_loss = tf.reduce_mean(tf.abs(input_A-cyc_A)) + tf.reduce_mean(tf.abs(input_B-cyc_B))\n",
        "\n",
        "g_loss_A = g_loss_A_1 + 10*cyc_loss\n",
        "g_loss_B = g_loss_B_1 + 10*cyc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-MjzWCssweL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Putting them together"
      ]
    },
    {
      "metadata": {
        "id": "n5JuFuAksz-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
        "d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
        "g_A_trainer = optimizer.minimize(g_loss_A, var_list=g_A_vars)\n",
        "g_B_trainer = optimizer.minimize(g_loss_B, var_list=g_B_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5HyxCCHs3f7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ]
    },
    {
      "metadata": {
        "id": "63gWGihGs5g3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(0,100):\n",
        "    # Define the learning rate schedule. The learning rate is kept\n",
        "    # constant upto 100 epochs and then slowly decayed\n",
        "    if(epoch < 100) :\n",
        "        curr_lr = 0.0002\n",
        "    else:\n",
        "        curr_lr = 0.0002 - 0.0002*(epoch-100)/100\n",
        "\n",
        "    # Running the training loop for all batches\n",
        "    for ptr in range(0,num_images):\n",
        "\n",
        "        # Train generator G_A->B\n",
        "        _, gen_B_temp = sess.run([g_A_trainer, gen_B],\n",
        "                                 feed_dict={input_A:A_input[ptr], input_B:B_input[ptr], lr:curr_lr})\n",
        "\n",
        "        # We need gen_B_temp because to calculate the error in training D_B\n",
        "        _ = sess.run([d_B_trainer],\n",
        "                     feed_dict={input_A:A_input[ptr], input_B:B_input[ptr], lr:curr_lr})\n",
        "\n",
        "        # Same for G_B->A and D_A as follow\n",
        "        _, gen_A_temp = sess.run([g_B_trainer, gen_A],\n",
        "                                 feed_dict={input_A:A_input[ptr], input_B:B_input[ptr], lr:curr_lr})\n",
        "        _ = sess.run([d_A_trainer],\n",
        "                     feed_dict={input_A:A_input[ptr], input_B:B_input[ptr], lr:curr_lr})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AaBT38WHtD9P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### generated image pool"
      ]
    },
    {
      "metadata": {
        "id": "BgHkWsOts9_c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_pool(self, num_gen, gen_img, gen_pool):\n",
        "    if(num_gen < pool_size):\n",
        "        gen_img_pool[num_gen] = gen_img\n",
        "        return gen_img\n",
        "    else :\n",
        "        p = random.random()\n",
        "        if p > 0.5:\n",
        "            # Randomly selecting an id to return for calculating the discriminator loss\n",
        "            random_id = random.randint(0,pool_size-1)\n",
        "            temp = gen_img_pool[random_id]\n",
        "            gen_pool[random_id] = gen_img\n",
        "            return temp\n",
        "        else :\n",
        "            return gen_img\n",
        "\n",
        "\n",
        "          gen_image_pool_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"gen_img_pool_A\")\n",
        "gen_image_pool_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"gen_img_pool_B\")\n",
        "\n",
        "gen_pool_rec_A = build_gen_discriminator(gen_image_pool_A, \"d_A\")\n",
        "gen_pool_rec_B = build_gen_discriminator(gen_image_pool_B, \"d_B\")\n",
        "\n",
        "# Also the discriminator loss will change as follow\n",
        "\n",
        "D_A_loss_2 = tf.reduce_mean(tf.square(gen_pool_rec_A))\n",
        "D_A_loss_2 = tf.reduce_mean(tf.square(gen_pool_rec_A))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}