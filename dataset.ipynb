{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dermond0917/SPARK_5/blob/master/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EW-6gDC9tEuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "e5bfe30d-6d7b-477f-c902-3796398a3512"
      },
      "cell_type": "code",
      "source": [
        "import helper\n",
        "helper.download_extract('celeba', data_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ace8a19b5cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'celeba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xjMGqQJ9tEvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "94d6cb68-3fee-4a37-b7c9-cb9c0a8b105b"
      },
      "cell_type": "code",
      "source": [
        "#snippet of Helper python file which preprocess the given image dataset.\n",
        "def get_image(image_path, width, height, mode):\n",
        "    \"\"\"\n",
        "    Read image from image_path\n",
        "    :param image_path: Path of image\n",
        "    :param width: Width of image\n",
        "    :param height: Height of image\n",
        "    :param mode: Mode of image\n",
        "    :return: Image data\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)\n",
        "if image.size != (width, height):  \n",
        "       \n",
        "        face_width = face_height = 108\n",
        "        j = (image.size[0] - face_width) // 2\n",
        "        i = (image.size[1] - face_height) // 2\n",
        "        image = image.crop([j, i, j + face_width, i + face_height])\n",
        "        image = image.resize([width, height], Image.BILINEAR)\n",
        "return np.array(image.convert(mode))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-72573704c1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mface_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m108\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0AI7QJOCtE0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from distutils.version import LooseVersion\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "# Check TensorFlow Version\n",
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))\n",
        "# Check for a GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tbu9vAONtE5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(z, out_channel_dim, is_train=True, alpha=0.2, keep_prob=0.5):\n",
        "  \n",
        "    with tf.variable_scope('generator', reuse=(not is_train)):\n",
        "        # First fully connected layer, 4x4x1024\n",
        "        fc = tf.layers.dense(z, 4*4*1024, use_bias=False)\n",
        "        fc = tf.reshape(fc, (-1, 4, 4, 1024))\n",
        "        bn0 = tf.layers.batch_normalization(fc, training=is_train)\n",
        "        lrelu0 = tf.maximum(alpha * bn0, bn0)\n",
        "        drop0 = tf.layers.dropout(lrelu0, keep_prob, training=is_train)\n",
        "        \n",
        "        # Deconvolution, 7x7x512\n",
        "        conv1 = tf.layers.conv2d_transpose(drop0, 512, 4, 1, 'valid', use_bias=False)\n",
        "        bn1 = tf.layers.batch_normalization(conv1, training=is_train)\n",
        "        lrelu1 = tf.maximum(alpha * bn1, bn1)\n",
        "        drop1 = tf.layers.dropout(lrelu1, keep_prob, training=is_train)\n",
        "        \n",
        "        # Deconvolution, 14x14x256\n",
        "        conv2 = tf.layers.conv2d_transpose(drop1, 256, 5, 2, 'same', use_bias=False)\n",
        "        bn2 = tf.layers.batch_normalization(conv2, training=is_train)\n",
        "        lrelu2 = tf.maximum(alpha * bn2, bn2)\n",
        "        drop2 = tf.layers.dropout(lrelu2, keep_prob, training=is_train)\n",
        "        \n",
        "        # Output layer, 28x28xn\n",
        "        logits = tf.layers.conv2d_transpose(drop2, out_channel_dim, 5, 2, 'same')\n",
        "        \n",
        "        out = tf.tanh(logits)\n",
        "        \n",
        "        return out\n",
        "tests.test_generator(generator, tf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iY4xco9FtE_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator(images, reuse=False, alpha=0.2, keep_prob=0.5):\n",
        "    \n",
        "    with tf.variable_scope('discriminator', reuse=reuse):\n",
        "        # Input layer is 28x28xn\n",
        "        # Convolutional layer, 14x14x64\n",
        "        conv1 = tf.layers.conv2d(images, 64, 5, 2, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
        "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
        "        drop1 = tf.layers.dropout(lrelu1, keep_prob)\n",
        "        \n",
        "        # Strided convolutional layer, 7x7x128\n",
        "        conv2 = tf.layers.conv2d(drop1, 128, 5, 2, 'same', use_bias=False)\n",
        "        bn2 = tf.layers.batch_normalization(conv2)\n",
        "        lrelu2 = tf.maximum(alpha * bn2, bn2)\n",
        "        drop2 = tf.layers.dropout(lrelu2, keep_prob)\n",
        "        \n",
        "        # Strided convolutional layer, 4x4x256\n",
        "        conv3 = tf.layers.conv2d(drop2, 256, 5, 2, 'same', use_bias=False)\n",
        "        bn3 = tf.layers.batch_normalization(conv3)\n",
        "        lrelu3 = tf.maximum(alpha * bn3, bn3)\n",
        "        drop3 = tf.layers.dropout(lrelu3, keep_prob)\n",
        "        \n",
        "        # fully connected\n",
        "        flat = tf.reshape(drop3, (-1, 4*4*256))\n",
        "        logits = tf.layers.dense(flat, 1)\n",
        "        out = tf.sigmoid(logits)\n",
        "        \n",
        "        return out, logits\n",
        "tests.test_discriminator(discriminator, tf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbbLZMNwtE-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_loss(input_real, input_z, out_channel_dim, alpha=0.2, smooth_factor=0.1):\n",
        "    \n",
        "    # TODO: Implement Function\n",
        "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
        "    \n",
        "    d_loss_real = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
        "                                                labels=tf.ones_like(d_model_real) * (1 - smooth_factor)))\n",
        "    \n",
        "    input_fake = generator(input_z, out_channel_dim, alpha=alpha)\n",
        "    d_model_fake, d_logits_fake = discriminator(input_fake, reuse=True, alpha=alpha)\n",
        "    \n",
        "    d_loss_fake = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))\n",
        "    \n",
        "    g_loss = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))\n",
        "return d_loss_real + d_loss_fake, g_loss\n",
        "tests.test_model_loss(model_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1f2KxaSotE4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reference: https://medium.com/coinmonks/celebrity-face-generation-using-gans-tensorflow-implementation-eaa2001eef86"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5b1uq6itiEQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}